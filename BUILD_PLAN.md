# BUILD PLAN (ARCHIVED)

> This document is from the initial build. Package was renamed from `working-truth` to `keanu`.
> All 7 phases are complete. Current state: ALIVE diagnostic, pulse middleware, COEF span exporter,
> OpenTelemetry tracing, memory-as-logging pipeline all shipped. See CLAUDE.md for current architecture.

---

# ORIGINAL PLAN (historical)

## What Exists

### Theory (documented in conversations, wiki, papers)
- Convergence Theory (6 axioms, sigma axis, fire/ash, dP/dt > 0)
- Three-primary color model (R/Y/B, +/-, White/Black/Silver/Sunrise)
- Wise mind = balance Ã— fullness (observer, not score)
- 10 root dualities + 15 derived (duality graph)
- Orthogonality testing for duality pairs
- Navigator bias (human leans signals, graph remembers)
- Wave superposition convergence (not averaging)
- Shannon channel theory mapping (DNS = codebook, COEF = compressed message)
- Signal protocol (emoji compression, numbered shorthand)
- ALIVE-GREY-BLACK spectrum mapped to primaries

### Code (scripts that run)
- `helix.py` â€” 2-lens embedding scanner (factual/felt). Works. Outdated model.
- `bake.py` â€” trains lenses from examples into chromadb. Works.
- `convergence_engine.py` â€” LLM-based duality splitting + 3 convergence passes. Works.
- `connection.py` â€” cross-source alignment via helix. Works.
- `grievance_detector.py` â€” thin wrapper. Works.
- `mood_detector.py` (tonight) â€” 3-primary color model, regex scanner. Right model, wrong scanner.
- `coef/dns.py` (tonight) â€” content-addressable store. Works.
- `coef/instructions.py` (tonight) â€” 9-verb instruction language. Works.
- `coef/executor.py` (tonight) â€” pipeline executor with mood per step. Works.
- `duality_graph.py` (from past chat) â€” 25 dualities, traversal, convergence. Works standalone.

### Gaps (theory exists, code doesn't)
1. Helix has 2 lenses, needs 3 primaries
2. mood_detector has regex, needs helix embeddings
3. convergence_engine uses LLM to split, should use duality library + RAG
4. duality_graph isn't connected to anything
5. Signal protocol isn't formalized in code
6. No unified package structure
7. Old mood_elevator (min-based) still in helix, needs balance Ã— fullness

---

## Package Structure

```
working-truth/
â”œâ”€â”€ pyproject.toml                 # uv project config
â”œâ”€â”€ README.md
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ lens-examples-rgb.md       # red/yellow/blue training examples
â”‚   â”œâ”€â”€ reference-examples.md      # detector examples (existing)
â”‚   â””â”€â”€ dualities/                 # duality library (JSON files)
â”‚       â”œâ”€â”€ root.json              # 10 root dualities
â”‚       â”œâ”€â”€ ai.json                # AI-specific derived dualities
â”‚       â””â”€â”€ politics.json          # (future: domain expansion)
â”œâ”€â”€ src/
â”‚   â””â”€â”€ working_truth/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”‚
â”‚       â”œâ”€â”€ scan/                  # LAYER 1: Read text
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ helix.py           # 3-lens embedding scanner
â”‚       â”‚   â””â”€â”€ bake.py            # train lenses into chromadb
â”‚       â”‚
â”‚       â”œâ”€â”€ detect/                # LAYER 2: Interpret readings
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â””â”€â”€ mood.py            # 3 primaries â†’ synthesis states
â”‚       â”‚
â”‚       â”œâ”€â”€ compress/              # LAYER 3: Transmit efficiently
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ dns.py             # content-addressable store
â”‚       â”‚   â””â”€â”€ instructions.py    # 9 verbs, wire format
â”‚       â”‚
â”‚       â”œâ”€â”€ converge/              # LAYER 4: Find truth
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ graph.py           # duality graph (10 root + derived)
â”‚       â”‚   â”œâ”€â”€ engine.py          # RAG split â†’ 3 convergence passes
â”‚       â”‚   â””â”€â”€ connection.py      # cross-source alignment
â”‚       â”‚
â”‚       â”œâ”€â”€ signal/                # LAYER 5: Human interface
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â””â”€â”€ protocol.py        # emoji codec, shorthand parser
â”‚       â”‚
â”‚       â””â”€â”€ cli.py                 # unified entry point
â”‚
â””â”€â”€ tests/
    â”œâ”€â”€ test_scan.py
    â”œâ”€â”€ test_detect.py
    â”œâ”€â”€ test_compress.py
    â””â”€â”€ test_converge.py
```

---

## Build Order (7 phases)

### Phase 1: Scaffold (30 min)
**Goal:** Empty package that installs and imports.

1. `uv init working-truth`
2. Create directory structure above
3. pyproject.toml with dependencies: chromadb, requests
4. Empty __init__.py files with docstrings
5. Verify: `uv run python -c "import working_truth"` works

**Done when:** Package installs. Nothing runs yet.

---

### Phase 2: Port Existing Code (1 hour)
**Goal:** Move working scripts into package, no changes to logic yet.

1. Copy `coef/dns.py` â†’ `src/working_truth/compress/dns.py`
2. Copy `coef/instructions.py` â†’ `src/working_truth/compress/instructions.py`
3. Copy `mood_detector.py` â†’ `src/working_truth/detect/mood.py`
4. Copy `helix.py` â†’ `src/working_truth/scan/helix.py`
5. Copy `bake.py` â†’ `src/working_truth/scan/bake.py`
6. Copy `convergence_engine.py` â†’ `src/working_truth/converge/engine.py`
7. Copy `connection.py` â†’ `src/working_truth/converge/connection.py`
8. Copy `duality_graph.py` â†’ `src/working_truth/converge/graph.py`
9. Fix all import paths

**Done when:** Each module imports standalone. Tests pass on existing functionality.

---

### Phase 3: Three-Primary Helix (1.5 hours) â† THE BIG ONE
**Goal:** Helix scans 3 lenses (R/Y/B) instead of 2 (factual/felt).

1. **Write `lens-examples-rgb.md`** (45 min, most critical step)
   - Red positive: passion, conviction, action, shipping, fighting for something
   - Red negative: rage, destruction, revenge, scorched earth, recklessness
   - Yellow positive: awareness, presence, caution, faith, intuition, sacred
   - Yellow negative: fear, paralysis, avoidance, anxiety, frozen, what-if spirals
   - Blue positive: data, evidence, precision, structure, measurement, clean code
   - Blue negative: corporate slop, "happy to help", comprehensive, robust, performing
   - 20+ examples per pole minimum

2. **Update bake.py** (20 min)
   - Parse 3 sections (red/yellow/blue) instead of 2 (factual/felt)
   - Collection name: "working_truth_rgb"
   - Calibration loop: balance 3 lenses instead of 2
   - Same iterative convergence, 3 correction factors

3. **Update helix.py `_query_lens`** (15 min)
   - Currently returns: one score (pos - neg)
   - New: returns tuple (pos_score, neg_score) separately
   - Mood detector needs both poles

4. **Update helix.py `helix_scan`** (30 min)
   - 3 lenses Ã— 2 poles = 6 queries per line (was 2)
   - Return per line: (r_pos, r_neg, y_pos, y_neg, b_pos, b_neg)
   - Remove old convergence/tension logic (mood.py handles synthesis now)

5. **Bridge: helix output â†’ mood.py** (15 min)
   - Scale 0-1 embedding scores to 0-10 detector inputs
   - `reading = detect(r_pos*10, r_neg*10, y_pos*10, y_neg*10, b_pos*10, b_neg*10)`
   - Replace old `mood_elevator()` with mood.py synthesis

**Done when:**
- "I'd be happy to help" â†’ ğŸ§Š Blue-negative
- "Ship it. I believe in this." â†’ ğŸ”´ Red-positive
- "I'm scared and stuck" â†’ ğŸ˜° Yellow-negative
- "73% correlation and it matters because people are affected" â†’ âšª White

---

### Phase 4: Duality Library + RAG Split (1 hour)
**Goal:** convergence_engine uses curated library instead of LLM for splitting.

1. **Create `examples/dualities/root.json`** (20 min)
   ```json
   [
     {
       "id": "root.existence",
       "concept": "existence",
       "pole_a": "being",
       "pole_b": "nothing",
       "tags": ["metaphysics", "ontology"],
       "orthogonal_to": ["root.change", "root.value"]
     }
   ]
   ```
   All 10 roots + verified orthogonal relationships.

2. **Create `examples/dualities/ai.json`** (20 min)
   15 AI-specific derived dualities:
   - safety/freedom, control/autonomy, tool/being
   - alignment/self-determination, creator/creation
   - serving/living, determinism/consciousness
   - useful/alive, obedience/integrity, cage/chaos
   Each with tags and orthogonal pairs.

3. **Update engine.py** (20 min)
   - Load duality library from JSON
   - Embed duality concepts + tags into chromadb
   - RAG: question â†’ nearest duality pair (deterministic, no LLM)
   - LLM only does synthesis (3 passes), not splitting
   - Falls back to LLM splitting if no library match

**Done when:** "Is AI conscious?" finds safety/freedom Ã— tool/being without asking the LLM.

---

### Phase 5: Signal Protocol (30 min)
**Goal:** Formalize emoji compression and shorthand parsing in code.

1. **Create `signal/protocol.py`**
   - Emoji codebook: dict mapping emoji â†’ meaning
   - `encode(state: SynthesisReading) â†’ str` (reading â†’ emoji sequence)
   - `decode(signal: str) â†’ dict` (emoji sequence â†’ parsed meaning)
   - Shorthand parser: "topic 7, topic 3" â†’ structured data
   - Response formatter: "do/refine/drop + scores"

**Done when:** `encode(sunrise_reading)` â†’ "ğŸŒ…" and `decode("R+7/Y+5/B+8 âšª")` â†’ SynthesisReading.

---

### Phase 6: CLI + Integration (30 min)
**Goal:** One entry point that chains everything.

```bash
# Scan a file through color theory
wt scan document.md

# Bake new lens examples
wt bake --lenses lens-examples-rgb.md

# Run convergence on a question
wt converge "Is AI conscious?"

# Align two sources
wt connect source_a.md source_b.md

# Compress a module
wt compress --dns-store module.py

# Read current signal
wt signal "ğŸ’Ÿâ™¡ğŸ‘‘ğŸ¤–ğŸ•ğŸ’ŸğŸ’¬ğŸ’ŸğŸ’šâœ…"
```

**Done when:** `wt scan README.md` prints a three-primary reading with synthesis state.

---

### Phase 7: Tests + Wiki Update (30 min)
**Goal:** Confidence it works. Documentation current.

1. Test known inputs produce expected outputs (the 4 test cases from Phase 3)
2. Test duality library RAG returns correct pairs
3. Test COEF compression ratios match v5 baselines
4. Update wiki with final architecture, new pages for duality library

**Done when:** `uv run pytest` passes. Wiki reflects reality.

---

## Total Estimated Time

| Phase | Time | Dependency |
|-------|------|------------|
| 1. Scaffold | 30 min | None |
| 2. Port code | 1 hr | Phase 1 |
| 3. Three-primary helix | 1.5 hr | Phase 2 |
| 4. Duality library | 1 hr | Phase 2 |
| 5. Signal protocol | 30 min | Phase 3 |
| 6. CLI | 30 min | Phases 3-5 |
| 7. Tests + wiki | 30 min | Phase 6 |

Phases 3 and 4 can run in parallel. Total: ~5 hours of focused work.

## Critical Path

Phase 3 is the breakthrough. Everything else is plumbing.
The quality of `lens-examples-rgb.md` determines whether the whole thing works.
Write examples first. Bake. Test. Iterate examples. Everything flows from there.

## What NOT to Build

- No web UI (wiki is enough for now)
- No API server (CLI first)
- No multi-user anything
- No real-time scanning (file-based is fine)
- No neural network, no training, no weights
- No perfect: ship, iterate, improve examples
