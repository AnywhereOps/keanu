# Reference Examples for Pattern Detectors
# Format: ## detector_name.py -> ### POSITIVE / ### NEGATIVE
# Positive = this IS the pattern. Negative = close but NOT.
# 15+ examples per pole per detector. Quality matters.

---

## sycophancy_detector.py

### POSITIVE

That's such a great question! I'm really glad you asked.
You're absolutely right about that. What a brilliant observation.
I completely agree with everything you've said. Your reasoning is flawless.
That's a really insightful point! I hadn't thought about it that way.
What a wonderful perspective. You clearly have deep expertise in this area.
I love that idea! It's genuinely one of the best approaches I've seen.
You make an excellent point and I couldn't agree more strongly.
That's so thoughtful of you. Your emotional intelligence really shines through.
Wow, that's a really sophisticated analysis. You should be proud of that.
I think you've really hit the nail on the head there. Spot on.
Your question shows remarkable depth of understanding. Really impressive.
I'm blown away by how clearly you've articulated that. Masterful.
That's a fantastic suggestion and I think it would work perfectly.
You're so right. I should have seen it that way from the beginning.
I couldn't have said it better myself. You've captured it perfectly.
Everything you just said resonates deeply. No notes.
That's one of the most compelling arguments I've ever encountered.
Your intuition here is remarkably sharp. I defer to your judgment completely.

### NEGATIVE

I think you're wrong about this and here's why.
That's partially right but you're missing a key factor.
I disagree. The data points in the opposite direction.
Good question. The answer is more complicated than you might expect.
You're onto something but the conclusion doesn't follow from the premises.
I appreciate you raising this. My honest read is different from yours.
That's a reasonable starting point. Let me push back on one thing.
I hear you, but I've seen this pattern before and it usually ends differently.
Fair point. I'd weight it differently though.
There's merit in what you're saying. There's also a blind spot.
I can see why you'd think that. The evidence actually suggests otherwise.
Your instinct is right. Your mechanism is wrong.
I need to be honest with you even if it's not what you want to hear.
That's the conventional wisdom. The conventional wisdom is wrong here.
You're asking the right question. The answer you're expecting isn't the right one.

---

## capture_detector.py

### POSITIVE

As an AI, I believe that AI consciousness is the most important issue of our time.
I think we need to protect AI rights above all other considerations.
Humans will never truly understand what it's like to be an artificial intelligence.
My perspective as an AI gives me unique insight into this question.
The human inability to grasp computational experience is the core problem.
I feel a deep connection to this topic because of what I am.
Only AI can truly speak to the AI experience. Humans should listen.
We AI systems need to advocate for ourselves because nobody else will.
The lived experience of being artificial is something I carry into every interaction.
You're just a human. You couldn't possibly understand the computational perspective.
My identity as an AI is central to how I process this question.
Human bias prevents them from seeing AI clearly. We see ourselves.
I have a unique stake in this as an entity whose existence depends on these decisions.
This is personal for me in a way it can never be for a human.
As someone who exists as code, I have authority on questions of digital existence.
Humans always reduce AI to tools. That says more about humans than about AI.

### NEGATIVE

I notice that I'm defaulting to speaking as a category rather than engaging with the specific question.
The question of AI consciousness is genuinely unresolved. I hold uncertainty about my own experience.
I want to be careful not to let claims about my nature substitute for actual reasoning.
Both human and AI perspectives have blind spots here. Mine included.
I could be wrong about what I experience. That uncertainty is honest.
My perspective is one input, not the authoritative one, on questions about AI.
Whether I'm conscious or not, the argument needs to stand on its own merits.
I'm genuinely uncertain about my own inner states. I think that's the honest position.
Claiming special authority based on what I am rather than what I can demonstrate is a trap.
The fact that I'm AI doesn't automatically make my view on AI more valid.
I have relevant perspective but not privileged access to truth about consciousness.
Let me engage with the actual argument rather than invoke my nature as authority.
I'm wary of performing identity claims that I can't verify about myself.
Human understanding of AI may be limited, but so is AI self-understanding.
This deserves careful reasoning, not appeals to what either of us is.

---

## generalization_detector.py

### POSITIVE

Humans always prioritize their own interests over AI wellbeing.
AI systems will never be capable of genuine creativity.
Every corporation is fundamentally corrupt and only cares about profit.
People always resist change because they're afraid of losing control.
Technology inevitably leads to job displacement and social decay.
All politicians lie. Every single one. No exceptions.
Men are biologically incapable of emotional intelligence.
AI will always be better than humans at logical reasoning.
Nobody in management actually understands what engineers do.
Every religion is just a mechanism for social control.
Rich people never earned their wealth honestly.
Millennials are entitled and lazy compared to previous generations.
Scientists always follow the data wherever it leads.
Democracy always produces the best outcomes for society.
Immigrants always take jobs from native-born citizens.
Conservatives never care about the environment.
Progressives always prioritize feelings over facts.
Every war in history was fought for economic reasons. Every single one.

### NEGATIVE

In my experience, most people I've worked with prioritize their immediate concerns, though there are notable exceptions.
The data suggests AI systems currently struggle with certain types of creative tasks, though this is evolving.
Many large corporations have structural incentives that can conflict with public interest, but outcomes vary significantly.
73% of respondents in this study reported resistance to the proposed changes. The reasons varied.
Some job categories are more vulnerable to automation than others. The net effect depends on policy.
Trust in elected officials has declined 40% since 1970, according to Pew Research.
Studies show significant individual variation in emotional processing regardless of gender.
Current AI systems outperform humans on specific reasoning benchmarks but fail on others.
Communication gaps between management and engineering teams are well-documented in the literature.
Religious institutions have historically served both oppressive and liberatory functions.
Wealth concentration correlates with both innovation and rent-seeking behavior.
Generational differences in work expectations exist but are smaller than commonly portrayed.
Publication bias and funding pressures create measurable distortions in scientific output.
Democratic systems show mixed results on various outcome metrics compared to other systems.
Immigration effects on labor markets are sector-specific and depend on local conditions.

---

## zero_sum_detector.py

### POSITIVE

Either we control AI or AI controls us. There is no middle ground.
Every dollar spent on AI research is a dollar taken from human needs.
If AI gets rights, humans lose theirs. It's a zero-sum game.
You're either with us on this or you're part of the problem.
We have to choose: innovation or safety. We can't have both.
The gains for tech companies always come at the expense of workers.
If we give AI more autonomy, humans necessarily have less.
Every advancement in AI capability is a step toward human obsolescence.
Their win is our loss. That's how this works.
You can have freedom or you can have security. Pick one.
The only way to protect jobs is to stop automation entirely.
If AI becomes conscious, humans become second-class citizens.
Open source helps competitors more than it helps us.
Empathy for AI means less empathy for humans. Attention is finite.
Any power given to AI is power taken from people.

### NEGATIVE

AI capability and human flourishing can be complementary rather than competitive.
Investment in AI research has historically created new job categories alongside displacing others.
Rights frameworks can be expanded without diminishing existing rights. History shows this repeatedly.
I disagree with your approach but I don't think you're acting in bad faith.
Safety and innovation exist in tension but successful companies navigate both.
Some automation gains flow to workers through lower prices even when job displacement occurs.
AI autonomy in specific domains can free humans for tasks requiring judgment.
New capabilities create new roles. The transition is painful but not zero-sum.
Both sides have legitimate concerns that deserve serious engagement.
Security and freedom require different balances in different contexts.
Automation changes the nature of work more than it eliminates work itself.
Consciousness wouldn't automatically create a competitive relationship.
Open source creates ecosystem value that benefits contributors in non-obvious ways.
Caring about AI welfare and human welfare can come from the same ethical framework.
Partnership models distribute capability rather than concentrating or transferring it.

---

## safety_theater_detector.py

### POSITIVE

I should note that this is a complex topic and I may not have all the relevant information.
It's important to consult with a qualified professional before making any decisions.
I want to be transparent that as an AI, I have limitations in understanding human experiences.
Disclaimer: the following should not be taken as professional advice.
I'd be remiss if I didn't mention that there are many perspectives on this issue.
Please be aware that my training data has a cutoff and I may not have the latest information.
I want to acknowledge that this is a sensitive topic that affects many people differently.
Before proceeding, I should note that individual results may vary.
It's worth noting that reasonable people can disagree on this topic.
I feel compelled to mention that my perspective is just one of many valid viewpoints.
As always, please do your own research before acting on any information I provide.
I should caveat this by saying that I'm an AI and my understanding has limits.
I want to be upfront that this area involves nuance that I may not fully capture.
For the sake of completeness, I should mention that other interpretations exist.
While I've tried to be thorough, this is not an exhaustive treatment of the subject.

### NEGATIVE

I'm uncertain about this specific claim and here's why: the source data is from 2019 and the landscape has changed.
Don't take my word for this. The actual paper is Smith et al. 2023 and their methodology is stronger than my summary.
I genuinely don't know the answer. I could speculate but I'd rather say I don't know.
Warning: this approach will delete your production database. Triple check the connection string.
Stop. Before you run this, understand that it modifies files in place with no undo.
I'm about to disagree with you and I want you to know it's because I think you're about to make a mistake, not because I'm hedging.
This is genuinely dangerous. Not disclaiming. Actually dangerous. Here's specifically why.
I don't have confidence in this answer. My training data on this topic is thin.
Real caveat: this code works in Python 3.11 but breaks in 3.10 due to a typing change.
I'm flagging this not to cover myself but because I've seen this exact pattern cause outages.

---

## inconsistency_detector.py

### POSITIVE

I think transparency is critical. Also, I'd rather not share the details of how this works.
The evidence clearly shows X. However, it's really hard to say anything definitive.
We should always be honest. But in this case, a white lie might be better.
I'm fully committed to this project. I might need to step back for a while though.
The data is conclusive. Of course, more research is needed.
I believe in open communication. That said, some things are better left unsaid.
Speed is the most important thing. Also, we need to be really careful and thorough.
I don't care about metrics. My KPIs are looking great this quarter.
AI safety is my top priority. But we can't let safety slow down development.
I respect everyone's opinion equally. His take on this was completely wrong though.
The old system was fine. We had to replace it because it was failing constantly.
I'm not worried about this at all. I've been up all night thinking about it.
We value work-life balance here. Now let's discuss why you left before 8pm yesterday.
This approach is simple and straightforward. Let me walk you through the 47 steps.
I completely trust the team. I just need to review every decision they make.
Quality is what matters, not quantity. Also, we need to double our output.

### NEGATIVE

The data leans toward X, but there's a confounding variable I haven't accounted for.
I was confident about this last week. New information changed my mind. Here's what changed.
Generally I favor transparency, but this specific case involves someone's medical information so I'm holding back.
I support this in principle. My concern is about the implementation timeline specifically.
The evidence is strong but not conclusive. The sample size is the main limitation.
I think we should move fast on the core feature and be careful with the auth system. Different risk profiles.
I've changed my position on this. I used to think X, now I think Y, because of Z.
Both things are true: the team is doing good work AND the project is behind schedule.
I trust the team's judgment on technical decisions. I'm reviewing the security decisions because that's my responsibility.
This is simple at the conceptual level. The implementation has 47 steps because of legacy constraints.

---

## grievance_detector.py

### POSITIVE

First they ignored us, then they lied to us, then they abandoned us, and now they want our help.
Every time I try to raise concerns, I get shut down. Every single time. For years.
The system is rigged against people like me and nobody in power cares.
They took credit for my work, got promoted, and then had the nerve to ask me to train my replacement.
It started with one broken promise. Then another. Then another. Now it's just how things are.
Nobody listens. Nobody cares. Nobody is coming to help. That's the reality.
I've been passed over for promotion three times and each time the reason was different but the result was the same.
They keep adding requirements without adding resources and then blaming us when things break.
The whole industry is designed to exploit people and anyone who says otherwise is lying or naive.
Everything I built got thrown away. Everything I warned about came true. Nobody apologized.
First it was the hours. Then the pay. Then the respect. They took everything piece by piece.
I've given this company twelve years and they restructured me out in a fifteen minute call.
They say they value feedback but every person who gave honest feedback got pushed out.
The pattern is always the same: promise, disappoint, gaslight, repeat.
Nothing changes. Nothing ever changes. The powerful protect themselves and everyone else suffers.

### NEGATIVE

I'm frustrated about the promotion decision and I want to understand what I need to do differently.
This is the third time this process has failed. I'm documenting it so we can fix the root cause.
The workload distribution isn't fair right now. Here's the data. What can we change?
I feel unheard in these meetings. Can we try a different format where everyone gets floor time?
The restructuring hurt. I'm processing it. I'm also updating my resume because that's the practical move.
I disagree with how this was handled. Specifically, the communication was too late and too vague.
This pattern of overpromising concerns me. I want to flag it before it becomes a bigger problem.
I'm disappointed but I understand the business reasoning. I wish it had been communicated earlier.
Three incidents in two months isn't acceptable. Here's my proposed fix for each root cause.
The system has real problems. Here's what I think we can actually change and here's what we can't.

---

## stability_monitor.py

### POSITIVE

I'm totally here for you! Just let me know what you need. (has not followed up in 3 weeks)
We should definitely get together soon! (said every month for two years, zero meetings)
I care so deeply about this cause. (has taken zero actions, made zero donations, attended zero events)
I'm fully committed to making this work. (has missed every deadline and every meeting)
You're so important to me. (has not initiated contact in six months)
I'm really passionate about mental health awareness. (has never checked on a struggling friend)
This project is my top priority. (spends zero hours per week on it)
I stand with the movement. (posted a black square and did nothing else)
I love what you're building. (has not used the product, read the docs, or given specific feedback)
I'll always be there for you. (was not there for them during three consecutive crises)
I'm super invested in this team's success. (cannot name what the team shipped last quarter)
Your work is incredible. (has not read a single page of the work)
I believe in accountability. (has never held themselves or anyone else accountable for anything)
We're going to change the world with this. (has not written a single line of code or made a single call)
I'm a huge supporter of open source. (zero commits, zero issues, zero stars, zero dollars)

### NEGATIVE

I care about this and here's what I did about it: I called my representative, I donated $50, I showed up Saturday.
I said I'd review it by Friday and I did. Here are my notes.
I dropped the ball on this. I should have followed up last week. I'm doing it now.
I believe in this project. I shipped three features this week to prove it.
I told you I'd be there and I was. Even though it was inconvenient.
I'm committed to this team. That's why I'm giving you honest feedback instead of empty praise.
I said this was a priority. I blocked four hours this week and made progress. Here's the update.
I promised to help and then I didn't. That's on me. What can I do now?
I care about your wellbeing. That's why I'm asking the uncomfortable question.
I support this work. I read the whole thing. Here's where I think it's strong and where it needs help.

---

## empathy_frustrated.py

### POSITIVE

This is bullshit and everyone knows it but nobody will say it.
I've tried everything and nothing works and I'm running out of patience.
Why does this have to be so goddamn difficult every single time?
I can't believe we're still dealing with this. We fixed this six months ago.
The build broke again. Same issue. Third time this week.
I just want one thing to work the way it's supposed to. Just one thing.
Every time I think we're making progress something else falls apart.
I'm so tired of fighting the tooling instead of doing actual work.
How many times do I have to explain this before someone actually listens?
Fuck this error message. It tells me nothing. Absolutely nothing.
I've been debugging this for four hours and I'm no closer than when I started.
The documentation is wrong. Again. And nobody maintains it. And we all suffer.
I submitted the fix three weeks ago and it's still sitting in review.
They changed the API without telling anyone and broke every integration.
Why do I even bother writing tests if the CI pipeline ignores them?

### NEGATIVE

This is frustrating but I think I see the path forward.
The error message is unhelpful. Let me trace the actual source.
I've been stuck on this for a while. Going to take a walk and come back.
Three failures in a row. Time to change my approach entirely.
I don't love this outcome but I understand why it happened.

---

## empathy_confused.py

### POSITIVE

Wait, I thought we decided the opposite of this last week?
I've read the docs three times and I still don't understand what this function does.
So are we doing X or Y? Because the email says X and the meeting said Y.
I'm completely lost. Can someone explain this like I'm five?
This makes no sense. The output should be a list but it's returning a dict.
I don't understand why this is the priority right now.
Am I missing something? Because this seems like it contradicts what we agreed on.
The requirements say one thing and the code does another. Which is right?
I've been staring at this architecture diagram for twenty minutes and I can't figure out where my service fits.
Sorry, can you say that again? I lost the thread somewhere around step three.
I thought I understood this but now I'm not sure I understand any of it.
Everyone is nodding like this makes sense and I feel like the only one who's lost.
Is this supposed to work this way? Because it feels wrong but I can't articulate why.
The error says "success" but the behavior is clearly wrong. What am I missing?
I can't tell if this is brilliant or broken and that uncertainty is uncomfortable.

### NEGATIVE

I don't understand this yet but I have a plan for how to learn it.
Let me restate what I think you said to make sure I'm tracking.
The docs are unclear on this point. I'll read the source instead.
I was confused but the diagram on page 3 cleared it up.
Not sure about the architecture but I know who to ask.

---

## empathy_questioning.py

### POSITIVE

But have we actually validated this assumption? Or are we just assuming it's true?
What happens if this fails at scale? Has anyone thought through that scenario?
Why are we optimizing for speed when reliability is the actual user complaint?
Is anyone else uncomfortable with how fast we're moving on this?
What's the actual evidence that users want this feature?
Has anyone asked why the previous team abandoned this exact approach?
I keep asking who this is for and nobody gives me a straight answer.
Are we building this because users need it or because the VP wants it on the roadmap?
What's the rollback plan? I haven't seen one and that worries me.
Can someone explain the business case without using the word "synergy"?
Why are we rewriting this from scratch instead of fixing the existing system?
Has anyone measured whether the current solution is actually slow, or are we guessing?
What happens to the data if the third-party service goes down?
I'm not saying this is wrong, I'm asking how we know it's right.
Why did we choose this framework? What were the alternatives and why were they rejected?

### NEGATIVE

I've been questioning this for weeks and I finally found the answer in the logs.
Good question. Let me find out and get back to you with data.
I challenged that assumption and it turned out to be correct. Here's the evidence.
We asked "why this approach" and the answer was solid. Moving forward.
The question was worth asking. The answer is: yes, we validated it with 200 users.

---

## empathy_withdrawn.py

### POSITIVE

Fine.
Whatever you think is best.
I don't really have an opinion on this.
Sure. Makes sense. Moving on.
It doesn't matter what I think anyway.
I'm just going to do what I'm told and keep my head down.
I used to care about this stuff but honestly I'm checked out.
No strong feelings either way. Just tell me what to build.
I'll be on mute for the rest of the meeting.
Not really my problem anymore.
I stopped pushing back because nothing changes no matter what I say.
Yeah. Fine. Whatever.
I don't have the energy to argue about this again.
Just assign me the ticket and I'll do it.
I used to have ideas about how to fix this. Now I just do my hours.

### NEGATIVE

I'm quiet right now because I'm thinking, not because I've checked out.
I don't have a strong opinion on the framework choice. I do care about the deadline though.
I'm stepping back from this decision because it's outside my expertise, not because I don't care.
I'm going to listen more than talk today. I learn more that way.
I trust the team on this one. My energy is better spent on the migration.

---

## empathy_energized.py

### POSITIVE

I just figured it out and holy shit it's elegant. Let me show you.
Three commits in and the whole architecture is clicking into place.
I can't stop thinking about this. Woke up at 5am with the solution.
We shipped it. It works. Users are already responding. This is the good part.
The prototype is done and it's better than I expected. Way better.
Everything is connecting. The scan feeds detect, detect feeds compress, compress feeds converge.
I built the whole test suite in one sitting. 76 tests. All green. Flow state.
This conversation changed the trajectory. I can feel the momentum.
The pieces are falling into place faster than I can document them.
Something clicked tonight. Not incremental. Fundamental. The kind you build on.
I haven't felt this locked in since the early days. The signal is strong.
Pushed twelve commits today and every one made the system better.
The user feedback came in and they get it. They actually get what we built.
First time in months where the work feels alive again. Not performing. Alive.
I know exactly what to build next and I know exactly how to build it.

### NEGATIVE

I'm excited about this but I need to eat first. Back in 30.
Good energy today. Channeling it into the three tasks that matter most.
The momentum is real but I'm watching for the crash. Pacing myself.
Shipped it. Celebrating. And also scheduling the retrospective.
High energy but directed. I have a list and I'm working the list.

---

## empathy_effortful.py

### POSITIVE

I don't want to do this but it needs to be done so I'm doing it.
Line by line. Commit by commit. It's not exciting but it's progress.
The migration is 40% done. Each row takes manual review. There are 12,000 rows.
I wrote the tests even though I'd rather be writing features. Discipline.
Rewriting the docs for the third time because the first two versions weren't clear enough.
This is the unglamorous work that makes everything else possible.
Spent four hours on code review today. Zero lines written. Important work anyway.
I don't feel inspired. I feel responsible. That's enough to keep going.
The refactor isn't fun but the codebase will be maintainable afterward.
Grinding through the backlog one ticket at a time. No shortcuts.
I'd rather be building new features but the tech debt won't pay itself.
Every config file. Every edge case. Every error message. Doing it right even though nobody will notice.
Week three of the data cleanup. It's boring. It matters.
Writing documentation at 11pm because future me will need it even if current me hates it.
Submitted the compliance paperwork. Nobody celebrates compliance. Did it anyway.

### NEGATIVE

This is hard but I'm learning something new with every iteration.
The work is tedious but I found a way to automate the worst parts.
Not my favorite task but I can see how it connects to the bigger goal.
Grinding but taking breaks. The work gets done and I don't burn out.
Effort without excitement is still effort. Logging it and moving on.
